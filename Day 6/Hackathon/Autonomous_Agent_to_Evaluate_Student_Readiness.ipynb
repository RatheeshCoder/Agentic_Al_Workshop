{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDl1JPW1XDUp",
        "outputId": "b0160cfc-8bc2-44f7-9b0a-fea611ebc329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "/bin/bash: line 1: ngrok: command not found\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langgraph langchain langchain-google-genai langchain-community\n",
        "!pip install -q chromadb sentence-transformers tavily-python\n",
        "!pip install -q PyPDF2 requests beautifulsoup4 python-dotenv\n",
        "!pip install -q langchain-core typing-extensions\n",
        "!pip install -q streamlit pyngrok\n",
        "!ngrok config add-authtoken 2ya3EMOR6COew8KQqMsDFjlgT1y_4J5KknWjtEuVZ3JMQw1gp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List, Any, Optional, TypedDict\n",
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Core imports\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Vector store and embeddings\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# API and utilities\n",
        "from tavily import TavilyClient\n",
        "import PyPDF2\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "6xY4YNNFXGRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyCidwla48YGqA2EzQBH_cVp9pA9XxvxO-s\"\n",
        "TAVILY_API_KEY = \"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\"\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.1,\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "chroma_client = chromadb.Client()\n"
      ],
      "metadata": {
        "id": "e_XkDAo_ZJHY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class StudentProfile:\n",
        "    \"\"\"Student profile data structure\"\"\"\n",
        "    name: str\n",
        "    languages: List[str]\n",
        "    frameworks: List[str]\n",
        "    domains: List[str]\n",
        "    projects: List[str]\n",
        "    models: List[str]\n",
        "    skills: List[str]\n",
        "    experience_years: int\n",
        "    education: str\n",
        "\n",
        "@dataclass\n",
        "class JobRequirements:\n",
        "    \"\"\"Job requirements data structure\"\"\"\n",
        "    role: str\n",
        "    required_skills: List[str]\n",
        "    preferred_skills: List[str]\n",
        "    tools: List[str]\n",
        "    frameworks: List[str]\n",
        "    experience_required: str\n",
        "    deliverables: List[str]\n",
        "    salary_range: str\n",
        "\n",
        "@dataclass\n",
        "class GapAnalysis:\n",
        "    \"\"\"Gap analysis result structure\"\"\"\n",
        "    student_name: str\n",
        "    target_role: str\n",
        "    skill_match_percentage: float\n",
        "    matched_skills: List[str]\n",
        "    missing_skills: List[str]\n",
        "    recommendations: List[str]\n",
        "    priority_areas: List[str]"
      ],
      "metadata": {
        "id": "VxxyFZPkZZVT"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentAnalyzerAgent:\n",
        "    \"\"\"Agent to analyze student profile and extract structured information\"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.name = \"Student Analyzer\"\n",
        "\n",
        "    def parse_resume_text(self, resume_text: str) -> StudentProfile:\n",
        "        \"\"\"Parse resume text and extract structured information\"\"\"\n",
        "\n",
        "        # Fixed prompt template - escaped curly braces properly\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are an expert resume analyzer. Extract structured information from the resume text.\n",
        "            Focus on technical skills, programming languages, frameworks, AI/ML models used, domains, and projects.\n",
        "\n",
        "            Return a JSON object with the following structure:\n",
        "            {{\n",
        "                \"name\": \"student name\",\n",
        "                \"languages\": [\"Python\", \"JavaScript\"],\n",
        "                \"frameworks\": [\"TensorFlow\", \"React\"],\n",
        "                \"domains\": [\"Computer Vision\", \"NLP\"],\n",
        "                \"projects\": [\"project descriptions\"],\n",
        "                \"models\": [\"CNN\", \"LSTM\", \"BERT\"],\n",
        "                \"skills\": [\"technical skills\"],\n",
        "                \"experience_years\": 0,\n",
        "                \"education\": \"degree information\"\n",
        "            }}\n",
        "            \"\"\"),\n",
        "            (\"human\", \"Resume text:\\n{resume_text}\")\n",
        "        ])\n",
        "\n",
        "        chain = prompt | self.llm | JsonOutputParser()\n",
        "        result = chain.invoke({\"resume_text\": resume_text})\n",
        "\n",
        "        return StudentProfile(**result)\n",
        "\n",
        "    def analyze_github_profile(self, github_url: str) -> Dict[str, Any]:\n",
        "        \"\"\"Analyze GitHub profile (simplified version)\"\"\"\n",
        "        # In a real implementation, you would use GitHub API\n",
        "        # This is a simplified version\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"Based on the GitHub URL provided, infer likely technologies and skills.\n",
        "            Return a JSON object with inferred skills, languages, and project types.\"\"\"),\n",
        "            (\"human\", \"GitHub URL: {github_url}\")\n",
        "        ])\n",
        "\n",
        "        chain = prompt | self.llm | JsonOutputParser()\n",
        "        result = chain.invoke({\"github_url\": github_url})\n",
        "\n",
        "        return result\n",
        "\n",
        "    def extract_project_skills(self, project_description: str) -> Dict[str, Any]:\n",
        "        \"\"\"Extract skills and technologies from project description\"\"\"\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"Analyze the project description and extract:\n",
        "            - Technologies used\n",
        "            - AI/ML models implemented\n",
        "            - Domain/industry focus\n",
        "            - Technical complexity level\n",
        "\n",
        "            Return as JSON.\"\"\"),\n",
        "            (\"human\", \"Project description:\\n{project_description}\")\n",
        "        ])\n",
        "\n",
        "        chain = prompt | self.llm | JsonOutputParser()\n",
        "        result = chain.invoke({\"project_description\": project_description})\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "E55dadmzZjqs"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JobRoleEvaluatorAgent:\n",
        "    \"\"\"Agent to evaluate job requirements using Tavily API and RAG\"\"\"\n",
        "\n",
        "    def __init__(self, llm, tavily_client):\n",
        "        self.llm = llm\n",
        "        self.tavily_client = tavily_client\n",
        "        self.name = \"Job Role Evaluator\"\n",
        "        self.setup_vector_store()\n",
        "\n",
        "    def setup_vector_store(self):\n",
        "        \"\"\"Setup vector store for job descriptions\"\"\"\n",
        "        try:\n",
        "            self.collection = chroma_client.get_collection(\"job_descriptions\")\n",
        "        except:\n",
        "            self.collection = chroma_client.create_collection(\n",
        "                name=\"job_descriptions\",\n",
        "                embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "                    model_name=\"all-MiniLM-L6-v2\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def search_job_descriptions(self, role: str, count: int = 5) -> List[Dict]:\n",
        "        \"\"\"Search for job descriptions using Tavily API\"\"\"\n",
        "\n",
        "        query = f\"{role} job description requirements skills 2024\"\n",
        "\n",
        "        try:\n",
        "            search_result = self.tavily_client.search(\n",
        "                query=query,\n",
        "                search_depth=\"advanced\",\n",
        "                max_results=count\n",
        "            )\n",
        "\n",
        "            job_descriptions = []\n",
        "            for result in search_result.get('results', []):\n",
        "                job_descriptions.append({\n",
        "                    'title': result.get('title', ''),\n",
        "                    'content': result.get('content', ''),\n",
        "                    'url': result.get('url', ''),\n",
        "                    'score': result.get('score', 0)\n",
        "                })\n",
        "\n",
        "            return job_descriptions\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error searching jobs: {e}\")\n",
        "            return []\n",
        "\n",
        "    def extract_job_requirements(self, job_descriptions: List[Dict]) -> JobRequirements:\n",
        "        \"\"\"Extract structured requirements from job descriptions\"\"\"\n",
        "\n",
        "        combined_content = \"\\n\\n\".join([jd['content'] for jd in job_descriptions])\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"Analyze multiple job descriptions and extract consolidated requirements.\n",
        "            Focus on the most commonly mentioned skills, tools, and requirements.\n",
        "\n",
        "            Return a JSON object with:\n",
        "            {\n",
        "                \"role\": \"job role title\",\n",
        "                \"required_skills\": [\"skill1\", \"skill2\", ...],\n",
        "                \"preferred_skills\": [\"skill1\", \"skill2\", ...],\n",
        "                \"tools\": [\"tool1\", \"tool2\", ...],\n",
        "                \"frameworks\": [\"framework1\", \"framework2\", ...],\n",
        "                \"experience_required\": \"X years\",\n",
        "                \"deliverables\": [\"deliverable1\", \"deliverable2\", ...],\n",
        "                \"salary_range\": \"salary information if available\"\n",
        "            }\n",
        "            \"\"\"),\n",
        "            (\"human\", \"Job descriptions:\\n{job_content}\")\n",
        "        ])\n",
        "\n",
        "        chain = prompt | self.llm | JsonOutputParser()\n",
        "        result = chain.invoke({\"job_content\": combined_content})\n",
        "\n",
        "        return JobRequirements(**result)\n",
        "\n",
        "    def store_job_descriptions(self, job_descriptions: List[Dict], role: str):\n",
        "        \"\"\"Store job descriptions in vector store for RAG\"\"\"\n",
        "\n",
        "        documents = []\n",
        "        metadatas = []\n",
        "        ids = []\n",
        "\n",
        "        for i, jd in enumerate(job_descriptions):\n",
        "            documents.append(jd['content'])\n",
        "            metadatas.append({\n",
        "                'title': jd['title'],\n",
        "                'url': jd['url'],\n",
        "                'role': role,\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "            ids.append(f\"{role}_{i}_{datetime.now().timestamp()}\")\n",
        "\n",
        "        self.collection.add(\n",
        "            documents=documents,\n",
        "            metadatas=metadatas,\n",
        "            ids=ids\n",
        "        )\n"
      ],
      "metadata": {
        "id": "gRvlwBs4Zpfl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GapAnalyzerAgent:\n",
        "    \"\"\"Agent to analyze gaps between student profile and job requirements\"\"\"\n",
        "\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.name = \"Gap Analyzer\"\n",
        "\n",
        "    def calculate_skill_match(self, student: StudentProfile, job: JobRequirements) -> float:\n",
        "        \"\"\"Calculate skill match percentage\"\"\"\n",
        "\n",
        "        student_skills = set(\n",
        "            student.languages + student.frameworks +\n",
        "            student.skills + student.models + student.domains\n",
        "        )\n",
        "\n",
        "        job_skills = set(\n",
        "            job.required_skills + job.preferred_skills +\n",
        "            job.tools + job.frameworks\n",
        "        )\n",
        "\n",
        "        # Normalize skills (convert to lowercase for comparison)\n",
        "        student_skills_normalized = {skill.lower().strip() for skill in student_skills}\n",
        "        job_skills_normalized = {skill.lower().strip() for skill in job_skills}\n",
        "\n",
        "        matches = student_skills_normalized.intersection(job_skills_normalized)\n",
        "\n",
        "        if len(job_skills_normalized) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        match_percentage = (len(matches) / len(job_skills_normalized)) * 100\n",
        "        return round(match_percentage, 2)\n",
        "\n",
        "    def identify_skill_gaps(self, student: StudentProfile, job: JobRequirements) -> Dict[str, List[str]]:\n",
        "        \"\"\"Identify matched and missing skills\"\"\"\n",
        "\n",
        "        student_skills = set(\n",
        "            student.languages + student.frameworks +\n",
        "            student.skills + student.models + student.domains\n",
        "        )\n",
        "\n",
        "        job_skills = set(\n",
        "            job.required_skills + job.preferred_skills +\n",
        "            job.tools + job.frameworks\n",
        "        )\n",
        "\n",
        "        student_skills_normalized = {skill.lower().strip() for skill in student_skills}\n",
        "        job_skills_normalized = {skill.lower().strip() for skill in job_skills}\n",
        "\n",
        "        matched = list(student_skills_normalized.intersection(job_skills_normalized))\n",
        "        missing = list(job_skills_normalized - student_skills_normalized)\n",
        "\n",
        "        return {\n",
        "            \"matched\": matched,\n",
        "            \"missing\": missing\n",
        "        }\n",
        "\n",
        "    def generate_recommendations(self, student: StudentProfile, job: JobRequirements, gap_analysis: Dict) -> List[str]:\n",
        "        \"\"\"Generate personalized recommendations\"\"\"\n",
        "\n",
        "        missing_skills = gap_analysis[\"missing\"]\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are a career advisor. Based on the student's current profile and missing skills for their target role,\n",
        "            provide specific, actionable recommendations. Focus on:\n",
        "            1. Courses or certifications to take\n",
        "            2. Projects to build\n",
        "            3. Tools to learn\n",
        "            4. Skills to develop\n",
        "\n",
        "            Make recommendations practical and prioritized.\"\"\"),\n",
        "            (\"human\", \"\"\"\n",
        "            Student Profile: {student_profile}\n",
        "            Target Role: {target_role}\n",
        "            Missing Skills: {missing_skills}\n",
        "            Matched Skills: {matched_skills}\n",
        "\n",
        "            Provide 5-7 specific recommendations.\n",
        "            \"\"\")\n",
        "        ])\n",
        "\n",
        "        chain = prompt | self.llm\n",
        "        result = chain.invoke({\n",
        "            \"student_profile\": json.dumps(asdict(student), indent=2),\n",
        "            \"target_role\": job.role,\n",
        "            \"missing_skills\": missing_skills,\n",
        "            \"matched_skills\": gap_analysis[\"matched\"]\n",
        "        })\n",
        "\n",
        "        # Extract recommendations from the response\n",
        "        recommendations = result.content.split('\\n')\n",
        "        recommendations = [rec.strip() for rec in recommendations if rec.strip() and len(rec.strip()) > 10]\n",
        "\n",
        "        return recommendations[:7]  # Return top 7 recommendations"
      ],
      "metadata": {
        "id": "2uP0PHv8ZuSO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentEvaluationSystem:\n",
        "    \"\"\"Main system orchestrating all agents using LangGraph\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.student_analyzer = StudentAnalyzerAgent(llm)\n",
        "        self.job_evaluator = JobRoleEvaluatorAgent(llm, tavily_client)\n",
        "        self.gap_analyzer = GapAnalyzerAgent(llm)\n",
        "        self.setup_graph()\n",
        "\n",
        "    def setup_graph(self):\n",
        "        \"\"\"Setup LangGraph workflow\"\"\"\n",
        "\n",
        "        # Define the state structure\n",
        "        class AgentState(TypedDict):\n",
        "            student_data: Dict[str, Any]\n",
        "            job_data: Dict[str, Any]\n",
        "            gap_analysis: Dict[str, Any]\n",
        "            final_report: Dict[str, Any]\n",
        "            target_role: str\n",
        "            current_step: str\n",
        "            messages: List[str]\n",
        "\n",
        "        # Create the graph\n",
        "        workflow = StateGraph(AgentState)\n",
        "\n",
        "        # Add nodes\n",
        "        workflow.add_node(\"analyze_student\", self.analyze_student_node)\n",
        "        workflow.add_node(\"evaluate_job\", self.evaluate_job_node)\n",
        "        workflow.add_node(\"analyze_gaps\", self.analyze_gaps_node)\n",
        "        workflow.add_node(\"generate_report\", self.generate_report_node)\n",
        "\n",
        "        # Set entry point and add edges\n",
        "        workflow.set_entry_point(\"analyze_student\")\n",
        "        workflow.add_edge(\"analyze_student\", \"evaluate_job\")\n",
        "        workflow.add_edge(\"evaluate_job\", \"analyze_gaps\")\n",
        "        workflow.add_edge(\"analyze_gaps\", \"generate_report\")\n",
        "        workflow.add_edge(\"generate_report\", END)\n",
        "\n",
        "        # Compile the graph\n",
        "        self.app = workflow.compile()\n",
        "\n",
        "    def analyze_student_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Node to analyze student profile\"\"\"\n",
        "        print(\"üîç Analyzing student profile...\")\n",
        "\n",
        "        # Initialize messages if not exists\n",
        "        if \"messages\" not in state:\n",
        "            state[\"messages\"] = []\n",
        "\n",
        "        state[\"messages\"].append(\"Starting student analysis...\")\n",
        "\n",
        "        resume_text = state[\"student_data\"][\"resume_text\"]\n",
        "        student_profile = self.student_analyzer.parse_resume_text(resume_text)\n",
        "\n",
        "        # If GitHub URL is provided, analyze it\n",
        "        if \"github_url\" in state[\"student_data\"]:\n",
        "            try:\n",
        "                github_analysis = self.student_analyzer.analyze_github_profile(\n",
        "                    state[\"student_data\"][\"github_url\"]\n",
        "                )\n",
        "                # Merge GitHub insights with student profile\n",
        "                if \"languages\" in github_analysis:\n",
        "                    student_profile.languages.extend(github_analysis[\"languages\"])\n",
        "                if \"skills\" in github_analysis:\n",
        "                    student_profile.skills.extend(github_analysis[\"skills\"])\n",
        "            except Exception as e:\n",
        "                state[\"messages\"].append(f\"GitHub analysis failed: {str(e)}\")\n",
        "\n",
        "        # If project description is provided, extract skills\n",
        "        if \"project_description\" in state[\"student_data\"]:\n",
        "            try:\n",
        "                project_analysis = self.student_analyzer.extract_project_skills(\n",
        "                    state[\"student_data\"][\"project_description\"]\n",
        "                )\n",
        "                if \"technologies\" in project_analysis:\n",
        "                    student_profile.skills.extend(project_analysis[\"technologies\"])\n",
        "            except Exception as e:\n",
        "                state[\"messages\"].append(f\"Project analysis failed: {str(e)}\")\n",
        "\n",
        "        state[\"student_data\"][\"profile\"] = asdict(student_profile)\n",
        "        state[\"current_step\"] = \"student_analyzed\"\n",
        "        state[\"messages\"].append(\"Student analysis completed\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    def evaluate_job_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Node to evaluate job requirements\"\"\"\n",
        "        print(\"üíº Evaluating job requirements...\")\n",
        "\n",
        "        state[\"messages\"].append(\"Starting job evaluation...\")\n",
        "\n",
        "        target_role = state[\"target_role\"]\n",
        "\n",
        "        try:\n",
        "            # Search for job descriptions\n",
        "            job_descriptions = self.job_evaluator.search_job_descriptions(target_role)\n",
        "\n",
        "            if job_descriptions:\n",
        "                # Store in vector store for future RAG\n",
        "                self.job_evaluator.store_job_descriptions(job_descriptions, target_role)\n",
        "\n",
        "                # Extract structured requirements\n",
        "                job_requirements = self.job_evaluator.extract_job_requirements(job_descriptions)\n",
        "                state[\"job_data\"] = {\n",
        "                    \"requirements\": asdict(job_requirements),\n",
        "                    \"raw_descriptions\": job_descriptions\n",
        "                }\n",
        "                state[\"messages\"].append(f\"Found {len(job_descriptions)} job descriptions\")\n",
        "            else:\n",
        "                # Fallback: generate generic requirements\n",
        "                state[\"job_data\"] = {\n",
        "                    \"requirements\": {\n",
        "                        \"role\": target_role,\n",
        "                        \"required_skills\": [\"Python\", \"Machine Learning\", \"Data Analysis\"],\n",
        "                        \"preferred_skills\": [\"TensorFlow\", \"PyTorch\"],\n",
        "                        \"tools\": [\"Git\", \"Docker\"],\n",
        "                        \"frameworks\": [\"Pandas\", \"NumPy\"],\n",
        "                        \"experience_required\": \"1-3 years\",\n",
        "                        \"deliverables\": [\"Model development\", \"Data pipeline\"],\n",
        "                        \"salary_range\": \"Not specified\"\n",
        "                    }\n",
        "                }\n",
        "                state[\"messages\"].append(\"Using fallback job requirements\")\n",
        "\n",
        "        except Exception as e:\n",
        "            state[\"messages\"].append(f\"Job evaluation error: {str(e)}\")\n",
        "            # Use fallback requirements\n",
        "            state[\"job_data\"] = {\n",
        "                \"requirements\": {\n",
        "                    \"role\": target_role,\n",
        "                    \"required_skills\": [\"Python\", \"Problem Solving\"],\n",
        "                    \"preferred_skills\": [\"Machine Learning\"],\n",
        "                    \"tools\": [\"Git\"],\n",
        "                    \"frameworks\": [\"Basic Programming\"],\n",
        "                    \"experience_required\": \"Entry level\",\n",
        "                    \"deliverables\": [\"Software development\"],\n",
        "                    \"salary_range\": \"Not specified\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "        state[\"current_step\"] = \"job_evaluated\"\n",
        "        state[\"messages\"].append(\"Job evaluation completed\")\n",
        "        return state\n",
        "\n",
        "    def analyze_gaps_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Node to analyze gaps\"\"\"\n",
        "        print(\"üìä Analyzing skill gaps...\")\n",
        "\n",
        "        state[\"messages\"].append(\"Starting gap analysis...\")\n",
        "\n",
        "        try:\n",
        "            student_profile = StudentProfile(**state[\"student_data\"][\"profile\"])\n",
        "            job_requirements = JobRequirements(**state[\"job_data\"][\"requirements\"])\n",
        "\n",
        "            # Calculate skill match\n",
        "            skill_match = self.gap_analyzer.calculate_skill_match(student_profile, job_requirements)\n",
        "\n",
        "            # Identify skill gaps\n",
        "            skill_gaps = self.gap_analyzer.identify_skill_gaps(student_profile, job_requirements)\n",
        "\n",
        "            # Generate recommendations\n",
        "            recommendations = self.gap_analyzer.generate_recommendations(\n",
        "                student_profile, job_requirements, skill_gaps\n",
        "            )\n",
        "\n",
        "            state[\"gap_analysis\"] = {\n",
        "                \"skill_match_percentage\": skill_match,\n",
        "                \"matched_skills\": skill_gaps[\"matched\"],\n",
        "                \"missing_skills\": skill_gaps[\"missing\"],\n",
        "                \"recommendations\": recommendations\n",
        "            }\n",
        "\n",
        "            state[\"messages\"].append(f\"Gap analysis completed - {skill_match}% match\")\n",
        "\n",
        "        except Exception as e:\n",
        "            state[\"messages\"].append(f\"Gap analysis error: {str(e)}\")\n",
        "            # Provide fallback analysis\n",
        "            state[\"gap_analysis\"] = {\n",
        "                \"skill_match_percentage\": 50.0,\n",
        "                \"matched_skills\": [\"python\", \"programming\"],\n",
        "                \"missing_skills\": [\"advanced skills needed\"],\n",
        "                \"recommendations\": [\"Continue learning and practicing\"]\n",
        "            }\n",
        "\n",
        "        state[\"current_step\"] = \"gaps_analyzed\"\n",
        "        return state\n",
        "\n",
        "    def generate_report_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Node to generate final report\"\"\"\n",
        "        print(\"üìã Generating final report...\")\n",
        "\n",
        "        state[\"messages\"].append(\"Generating final report...\")\n",
        "\n",
        "        try:\n",
        "            student_name = state[\"student_data\"][\"profile\"][\"name\"]\n",
        "            target_role = state[\"target_role\"]\n",
        "            gap_analysis = state[\"gap_analysis\"]\n",
        "\n",
        "            # Create gap analysis object\n",
        "            gap_report = GapAnalysis(\n",
        "                student_name=student_name,\n",
        "                target_role=target_role,\n",
        "                skill_match_percentage=gap_analysis[\"skill_match_percentage\"],\n",
        "                matched_skills=gap_analysis[\"matched_skills\"],\n",
        "                missing_skills=gap_analysis[\"missing_skills\"],\n",
        "                recommendations=gap_analysis[\"recommendations\"],\n",
        "                priority_areas=gap_analysis[\"missing_skills\"][:5]  # Top 5 priority areas\n",
        "            )\n",
        "\n",
        "            state[\"final_report\"] = asdict(gap_report)\n",
        "            state[\"messages\"].append(\"Report generated successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            state[\"messages\"].append(f\"Report generation error: {str(e)}\")\n",
        "            # Provide fallback report\n",
        "            state[\"final_report\"] = {\n",
        "                \"student_name\": \"Student\",\n",
        "                \"target_role\": state[\"target_role\"],\n",
        "                \"skill_match_percentage\": 0.0,\n",
        "                \"matched_skills\": [],\n",
        "                \"missing_skills\": [],\n",
        "                \"recommendations\": [\"Please check your input data\"],\n",
        "                \"priority_areas\": []\n",
        "            }\n",
        "\n",
        "        state[\"current_step\"] = \"report_generated\"\n",
        "        return state\n",
        "\n",
        "    def evaluate_student(self, student_data: Dict[str, Any], target_role: str) -> GapAnalysis:\n",
        "        \"\"\"Main method to evaluate student readiness\"\"\"\n",
        "\n",
        "        initial_state = {\n",
        "            \"student_data\": student_data,\n",
        "            \"job_data\": {},\n",
        "            \"gap_analysis\": {},\n",
        "            \"final_report\": {},\n",
        "            \"target_role\": target_role,\n",
        "            \"current_step\": \"initialized\",\n",
        "            \"messages\": []\n",
        "        }\n",
        "\n",
        "        # Run the workflow\n",
        "        final_state = self.app.invoke(initial_state)\n",
        "\n",
        "        return GapAnalysis(**final_state[\"final_report\"])"
      ],
      "metadata": {
        "id": "DDMUCJC8Z1Ne"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"Extract text from PDF file\"\"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def format_report(gap_analysis: GapAnalysis) -> str:\n",
        "    \"\"\"Format the gap analysis report\"\"\"\n",
        "\n",
        "    report = f\"\"\"\n",
        "üéì **Student Readiness Evaluation Report**\n",
        "===============================================\n",
        "\n",
        "üë®‚Äçüéì **Student:** {gap_analysis.student_name}\n",
        "üéØ **Target Role:** {gap_analysis.target_role}\n",
        "üìä **Skill Match Score:** {gap_analysis.skill_match_percentage}%\n",
        "\n",
        "‚úÖ **Matched Skills ({len(gap_analysis.matched_skills)}):**\n",
        "{chr(10).join([f\"   ‚Ä¢ {skill.title()}\" for skill in gap_analysis.matched_skills[:10]])}\n",
        "\n",
        "‚ùå **Missing Skills ({len(gap_analysis.missing_skills)}):**\n",
        "{chr(10).join([f\"   ‚Ä¢ {skill.title()}\" for skill in gap_analysis.missing_skills[:10]])}\n",
        "\n",
        "üìà **Recommendations:**\n",
        "{chr(10).join([f\"   {i+1}. {rec}\" for i, rec in enumerate(gap_analysis.recommendations)])}\n",
        "\n",
        "üéØ **Priority Areas to Focus:**\n",
        "{chr(10).join([f\"   ‚Ä¢ {area.title()}\" for area in gap_analysis.priority_areas])}\n",
        "\n",
        "===============================================\n",
        "Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "\"\"\"\n",
        "\n",
        "    return report\n",
        "\n",
        "# Example usage and testing\n",
        "def main():\n",
        "    \"\"\"Main function to demonstrate the system\"\"\"\n",
        "\n",
        "    print(\"üöÄ Starting Student Readiness Evaluation System...\")\n",
        "\n",
        "    # Initialize the system\n",
        "    evaluation_system = StudentEvaluationSystem()\n",
        "\n",
        "    # Sample student data\n",
        "    sample_student_data = {\n",
        "        \"resume_text\": \"\"\"\n",
        "        John Doe\n",
        "        Computer Science Graduate\n",
        "\n",
        "        Skills: Python, TensorFlow, Machine Learning, Computer Vision, OpenCV\n",
        "        Experience:\n",
        "        - Developed object detection system using YOLOv5\n",
        "        - Built a recommendation system using collaborative filtering\n",
        "        - Created a web application using Flask and React\n",
        "\n",
        "        Projects:\n",
        "        - Autonomous Vehicle Lane Detection using CNN\n",
        "        - E-commerce Recommendation Engine\n",
        "        - Stock Price Prediction using LSTM\n",
        "\n",
        "        Education: B.Tech in Computer Science\n",
        "        \"\"\",\n",
        "        \"github_url\": \"https://github.com/johndoe\",\n",
        "        \"project_description\": \"\"\"\n",
        "        Developed an autonomous vehicle lane detection system using Convolutional Neural Networks.\n",
        "        Used OpenCV for image processing, TensorFlow for model training, and deployed the model\n",
        "        using Flask API. The system achieved 94% accuracy on test dataset.\n",
        "        \"\"\"\n",
        "    }\n",
        "\n",
        "    target_role = \"Computer Vision Engineer\"\n",
        "\n",
        "    try:\n",
        "        # Run evaluation\n",
        "        result = evaluation_system.evaluate_student(sample_student_data, target_role)\n",
        "\n",
        "        # Display results\n",
        "        print(format_report(result))\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during evaluation: {e}\")\n",
        "        return None\n",
        "\n",
        "# Interactive function for Google Colab\n",
        "def evaluate_student_interactive():\n",
        "    \"\"\"Interactive function for easy testing in Google Colab\"\"\"\n",
        "\n",
        "    print(\"üéì Student Readiness Evaluation System\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Get user input\n",
        "    student_name = input(\"Enter student name: \")\n",
        "    resume_text = input(\"Enter resume/profile text: \")\n",
        "    github_url = input(\"Enter GitHub URL (optional): \")\n",
        "    project_description = input(\"Enter project description (optional): \")\n",
        "    target_role = input(\"Enter target job role: \")\n",
        "\n",
        "    # Prepare student data\n",
        "    student_data = {\n",
        "        \"resume_text\": f\"{student_name}\\n{resume_text}\"\n",
        "    }\n",
        "\n",
        "    if github_url.strip():\n",
        "        student_data[\"github_url\"] = github_url.strip()\n",
        "\n",
        "    if project_description.strip():\n",
        "        student_data[\"project_description\"] = project_description.strip()\n",
        "\n",
        "    # Initialize and run evaluation\n",
        "    evaluation_system = StudentEvaluationSystem()\n",
        "\n",
        "    try:\n",
        "        result = evaluation_system.evaluate_student(student_data, target_role)\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(format_report(result))\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üéØ Student Readiness Evaluation System Loaded!\")\n",
        "    print(\"\\nAvailable functions:\")\n",
        "    print(\"1. main() - Run with sample data\")\n",
        "    print(\"2. evaluate_student_interactive() - Interactive evaluation\")\n",
        "    print(\"3. run_tests() - Run automated tests\")\n",
        "    print(\"\\nDon't forget to set your API keys:\")\n",
        "    print(\"- GOOGLE_API_KEY for Gemini\")\n",
        "    print(\"- TAVILY_API_KEY for Tavily search\")\n",
        "\n",
        "    !streamlit run app.py &> /dev/null &\n",
        "    url = ngrok.connect(8501)\n",
        "    print(\"üîó Click this link to open your app:\", url)\n",
        "\n",
        "    main()\n",
        "    evaluate_student_interactive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sjoDUsIZ7PQ",
        "outputId": "16febabf-0b6c-478a-ce40-c4c0a6d110b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Student Readiness Evaluation System Loaded!\n",
            "\n",
            "Available functions:\n",
            "1. main() - Run with sample data\n",
            "2. evaluate_student_interactive() - Interactive evaluation\n",
            "3. run_tests() - Run automated tests\n",
            "\n",
            "Don't forget to set your API keys:\n",
            "- GOOGLE_API_KEY for Gemini\n",
            "- TAVILY_API_KEY for Tavily search\n",
            "üöÄ Starting Student Readiness Evaluation System...\n",
            "üîç Analyzing student profile...\n",
            "üíº Evaluating job requirements...\n",
            "üìä Analyzing skill gaps...\n",
            "üìã Generating final report...\n",
            "\n",
            "üéì **Student Readiness Evaluation Report**\n",
            "===============================================\n",
            "\n",
            "üë®‚Äçüéì **Student:** John Doe\n",
            "üéØ **Target Role:** Computer Vision Engineer\n",
            "üìä **Skill Match Score:** 40.0%\n",
            "\n",
            "‚úÖ **Matched Skills (2):**\n",
            "   ‚Ä¢ Python\n",
            "   ‚Ä¢ Machine Learning\n",
            "\n",
            "‚ùå **Missing Skills (3):**\n",
            "   ‚Ä¢ Basic Programming\n",
            "   ‚Ä¢ Problem Solving\n",
            "   ‚Ä¢ Git\n",
            "\n",
            "üìà **Recommendations:**\n",
            "   1. John's profile shows a strong foundation in Computer Vision, but lacks some fundamental and crucial professional skills.  Here's a prioritized plan to bridge the gap:\n",
            "   2. **1. Solidify Foundational Programming Skills:**\n",
            "   3. * **Recommendation:** Enroll in a structured online course focusing on fundamental programming concepts in Python.  This should cover data structures (lists, dictionaries, sets), algorithms (searching, sorting), object-oriented programming (OOP), and basic debugging techniques.\n",
            "   4. * **Course Suggestion:**  Consider courses on Coursera, edX, or Udemy focusing on \"Python for Beginners\" or \"Data Structures and Algorithms in Python.\"  Look for courses with good reviews and practical exercises.\n",
            "   5. **2. Enhance Problem-Solving Abilities:**\n",
            "   6. * **Recommendation:** Actively participate in coding challenges on platforms like HackerRank, LeetCode, or Codewars.  Focus on problems related to data structures and algorithms.  This will improve your logical thinking and problem-solving skills, crucial for debugging and designing efficient computer vision solutions.\n",
            "   7. * **Specific Action:** Start with easier problems and gradually increase the difficulty.  Focus on understanding the solution approach rather than just finding the answer.  Analyze your code for efficiency and readability.\n",
            "\n",
            "üéØ **Priority Areas to Focus:**\n",
            "   ‚Ä¢ Basic Programming\n",
            "   ‚Ä¢ Problem Solving\n",
            "   ‚Ä¢ Git\n",
            "\n",
            "===============================================\n",
            "Generated on: 2025-06-16 07:30:08\n",
            "\n",
            "üéì Student Readiness Evaluation System\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}